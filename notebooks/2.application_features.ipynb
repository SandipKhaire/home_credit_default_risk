{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numpy and pandas for data manipulation\n",
    "import numpy as np\n",
    "import pandas as pd \n",
    "\n",
    "# sklearn preprocessing for dealing with categorical variables\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# File system manangement\n",
    "import os\n",
    "\n",
    "# Suppress warnings \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# matplotlib and seaborn for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import io\n",
    "from openpyxl.drawing.image import Image\n",
    "import sys\n",
    "# Add the parent directory to the sys.path\n",
    "parent_dir = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "sys.path.append(parent_dir)\n",
    "\n",
    "from utils.eda import  categorical_univariate_summary,numerical_univariate_summary\n",
    "from src.utils.feature_engineering import compute_ratio_columnwise\n",
    "\n",
    "pd.set_option(\"display.max_columns\", None)  # Show all columns\n",
    "pd.set_option(\"display.max_rows\", None)     # Show all rows (optional)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Data\n",
    "app_train = pd.read_csv('../data/raw/app_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training Data shape : {app_train.shape}\")\n",
    "app_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The training data has 215257 observations (each one a separate loan) and 122 features (variables) including the `TARGET` (the label we want to predict)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing data features\n",
    "app_test= pd.read_csv('../data/raw/app_test.csv')\n",
    "print('Testing data shape: ', app_test.shape)\n",
    "app_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis\n",
    "\n",
    "Exploratory Data Analysis (EDA) is an open-ended process where we calculate statistics and make figures to find trends, anomalies, patterns, or relationships within the data. The goal of EDA is to learn what our data can tell us. It generally starts out with a high level overview, then narrows in to specific areas as we find intriguing areas of the data. The findings may be interesting in their own right, or they can be used to inform our modeling choices, such as by helping us decide which features to use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine the Distribution of the Target Column\n",
    "\n",
    "The target is what we are asked to predict: either a 0 for the loan was repaid on time, or a 1 indicating the client had payment difficulties i.e he/she had late payment more than X days on at least one of the first Y installments of the loan in our sample. We can first examine the number of loans falling into each category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts\n",
    "counts = app_train['TARGET'].value_counts()\n",
    "# Get percentages\n",
    "percentages = app_train['TARGET'].value_counts(normalize=True) * 100\n",
    "# Combine counts and percentages into a single DataFrame\n",
    "app_train_target = pd.DataFrame({'Count': counts, 'Percentage': percentages})\n",
    "print(app_train_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get counts\n",
    "counts = app_test['TARGET'].value_counts()\n",
    "# Get percentages\n",
    "percentages = app_test['TARGET'].value_counts(normalize=True) * 100\n",
    "# Combine counts and percentages into a single DataFrame\n",
    "app_test_target = pd.DataFrame({'Count': counts, 'Percentage': percentages})\n",
    "print(app_test_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this information, we see this is an imbalanced class problem. There are far more loans that were repaid on time than loans that were not repaid."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of each type of column\n",
    "app_train.dtypes.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(app_train.select_dtypes(include=['object']).columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_description = pd.read_csv('../data/raw/HomeCredit_columns_description.csv', encoding = 'latin1',usecols=['Table', 'Row', 'Description'])\n",
    "data_dict = data_description.loc[data_description['Table'] == 'application_{train|test}.csv',['Row', 'Description']].\\\n",
    "                     set_index('Row')['Description'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select categorical columns (object type)\n",
    "categorical_columns = app_train.select_dtypes(include=['object']).columns.tolist()\n",
    "# Select numeric columns with unique values <= 21\n",
    "numeric_categorical_columns = [\n",
    "    col for col in app_train.select_dtypes(include=['number']).columns\n",
    "    if app_train[col].nunique() <= 21\n",
    "]\n",
    "# Combine both lists\n",
    "final_categorical_columns = categorical_columns + numeric_categorical_columns\n",
    "print(len(final_categorical_columns))\n",
    "# Get all columns in the DataFrame\n",
    "all_columns = app_train.columns.tolist()\n",
    "# Get remaining columns (i.e., columns not in final_categorical_columns)\n",
    "numeric_columns = [col for col in all_columns if col not in final_categorical_columns]\n",
    "print(len(numeric_columns))\n",
    "print(len(all_columns))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the summary and save to the specified path\n",
    "categorical_univariate_summary(app_train, final_categorical_columns,data_dict=data_dict, save_path=\"../reports/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets remove CODE_GENDER=XNA  rows\n",
    "\n",
    "#Features not to use \n",
    "#['NAME_CONTRACT_TYPE','CODE_GENDER','NAME_FAMILY_STATUS','OCCUPATION_TYPE','HOUSETYPE_MODE',\n",
    "#'FONDKAPREMONT_MODE','WALLSMATERIAL_MODE','EMERGENCYSTATE_MODE',]\n",
    "\n",
    "# Categorical to binary encoding\n",
    "#['FLAG_OWN_CAR','FLAG_OWN_REALTY',\n",
    "\n",
    "# Convert categorical column to 'category' dtype\n",
    "#df['Category'] = df['Category'].astype('category')\n",
    "#['NAME_TYPE_SUITE','NAME_INCOME_TYPE','NAME_EDUCATION_TYPE','NAME_HOUSING_TYPE','WEEKDAY_APPR_PROCESS_START',\n",
    "#'ORGANIZATION_TYPE',]\n",
    "\n",
    "# Convert categorical column to label encoding\n",
    "\n",
    "\n",
    "# numerical variables to use\n",
    "#['CNT_CHILDREN','FLAG_MOBIL','FLAG_EMP_PHONE','FLAG_WORK_PHONE','FLAG_CONT_MOBILE','FLAG_EMAIL',\n",
    "# 'CNT_FAM_MEMBERS','REGION_RATING_CLIENT','REGION_RATING_CLIENT_W_CITY','REG_REGION_NOT_LIVE_REGION',\n",
    "#'REG_REGION_NOT_WORK_REGION','DEF_30_CNT_SOCIAL_CIRCLE','DEF_60_CNT_SOCIAL_CIRCLE','FLAG_DOCUMENT_2','FLAG_DOCUMENT_3',\n",
    "#'FLAG_DOCUMENT_6','FLAG_DOCUMENT_8','AMT_REQ_CREDIT_BUREAU_HOUR','AMT_REQ_CREDIT_BUREAU_DAY','AMT_REQ_CREDIT_BUREAU_WEEK',\n",
    "#'AMT_REQ_CREDIT_BUREAU_QRT']\n",
    "\n",
    "# OTHER FLAG DOCUMENT VARIABLES WE DIDN'T SELECTED BECAUSE OF LOW VARIANCE IN IT\n",
    "\n",
    "\n",
    "# also check if categories are fix or is there any chance of getting new categories then handle it\n",
    "#['NAME_INCOME_TYPE',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_univariate_summary(app_train, numerical_columns=numeric_columns,data_dict=data_dict, save_path=\"../reports/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Numerical variables to use and strategy\n",
    "- Income of the client variable AMT_INCOME_TOTAL has outliers  and cann't be used in absolute term directly hence\n",
    "needs to do some feature enginering to use it.\n",
    "- AMT_CREDIT also has some outliers and skewd \n",
    "\n",
    "Feature Creation:\n",
    "1. AMT_CREDIT/AMT_INCOME_TOTAL  -- for this make sure quality check that both should not null and AMT_INCOME_TOTAL is not zero\n",
    "2. AMT_ANNUITY/AMT_INCOME_TOTAL --> decide how to handle if any of the null \n",
    "3. AMT_CREDIT/AMT_GOODS_PRICE --> how to handle if any null or missing\n",
    "4. DAYS_BIRTH/-365 -->age of the client\n",
    "5. DAYS_EMPLOYED/-365 if DAYS_EMPLOYED<0 and np.nan impute DAYS_EMPLOYED>0 if  -->employement age \n",
    "\n",
    "# Direct to use\n",
    "['REGION_POPULATION_RELATIVE','employment_years','DAYS_REGISTRATION','DAYS_ID_PUBLISH','HOUR_APPR_PROCESS_START','EXT_SOURCE_1',\n",
    "'EXT_SOURCE_2','EXT_SOURCE_3','DAYS_LAST_PHONE_CHANGE','AMT_REQ_CREDIT_BUREAU_MON','AMT_REQ_CREDIT_BUREAU_YEAR']\n",
    "\n",
    "# Not to use directly\n",
    "['AMT_CREDIT','AMT_INCOME_TOTAL','AMT_ANNUITY','AMT_GOODS_PRICE','DAYS_BIRTH','DAYS_EMPLOYED']\n",
    "\n",
    "# New Features Created and to use\n",
    "['AMT_CREDIT_AMT_INCOME_TOTAL_ratio','Client_Age','AMT_ANNUITY_AMT_INCOME_TOTAL_ratio','AMT_CREDIT_AMT_GOODS_PRICE_ratio','employment_age']\n",
    "\n",
    "- IMP Notes: Before live prediction we need to setup feature proper validation and if valid then only we should predict otherwise not.\n",
    "THis we can do only for higher significant or important features because they only drive the decision .i.e if significant features are not available then don't do predictions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Domain Knwoledge Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets remove CODE_GENDER=XNA\n",
    "app_train = app_train.loc[app_train['CODE_GENDER'] != 'XNA']\n",
    "app_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function\n",
    "app_train['AMT_CREDIT_AMT_INCOME_TOTAL_ratio'] = compute_ratio_columnwise(app_train, 'AMT_CREDIT', 'AMT_INCOME_TOTAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function\n",
    "app_train['AMT_ANNUITY_AMT_INCOME_TOTAL_ratio'] = compute_ratio_columnwise(app_train, 'AMT_ANNUITY', 'AMT_INCOME_TOTAL')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply function\n",
    "app_train['AMT_CREDIT_AMT_GOODS_PRICE_ratio'] = compute_ratio_columnwise(app_train, 'AMT_CREDIT', 'AMT_GOODS_PRICE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train[\"Client_Age\"] = (app_train[\"DAYS_BIRTH\"]/(-365)).round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train['employment_years'] = np.where(app_train['DAYS_EMPLOYED'] < 0,  (app_train[\"DAYS_EMPLOYED\"] / -365).round(2),  np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train[\"employment_age\"] = np.where(app_train[\"employment_years\"].isna(),  -1,  \n",
    "                              np.where(app_train[\"Client_Age\"] > app_train[\"employment_years\"],\\\n",
    "                                        app_train[\"Client_Age\"] - app_train[\"employment_years\"], -2) \n",
    "                                # f1 > f2 -> f1 - f2, else NaN\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train['AMT_CREDIT_AMT_ANNUITY_ratio'] = compute_ratio_columnwise(app_train, 'AMT_CREDIT', 'AMT_ANNUITY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (12, 20))\n",
    "# iterate through the new features\n",
    "for i, feature in enumerate(['AMT_CREDIT_AMT_GOODS_PRICE_ratio','AMT_ANNUITY_AMT_INCOME_TOTAL_ratio',\\\n",
    "                             'AMT_CREDIT_AMT_INCOME_TOTAL_ratio','employment_years','employment_age','AMT_CREDIT_AMT_ANNUITY_ratio']):\n",
    "    \n",
    "    # create a new subplot for each source\n",
    "    plt.subplot(6, 1, i + 1)\n",
    "    # plot repaid loans\n",
    "    sns.kdeplot(app_train.loc[app_train['TARGET'] == 0, feature], label = 'target == 0')\n",
    "    # plot loans that were not repaid\n",
    "    sns.kdeplot(app_train.loc[app_train['TARGET'] == 1, feature], label = 'target == 1')\n",
    "    \n",
    "    # Label the plots\n",
    "    plt.title('Distribution of %s by Target Value' % feature)\n",
    "    plt.xlabel('%s' % feature); plt.ylabel('Density')\n",
    "    plt.legend()\n",
    "    \n",
    "plt.tight_layout(h_pad = 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_features = ['FLAG_OWN_CAR','FLAG_OWN_REALTY','NAME_TYPE_SUITE',\\\n",
    "                        'NAME_INCOME_TYPE','NAME_EDUCATION_TYPE','NAME_HOUSING_TYPE',\\\n",
    "                        'WEEKDAY_APPR_PROCESS_START','ORGANIZATION_TYPE',]\n",
    "\n",
    "numerical_features =   ['CNT_CHILDREN','FLAG_MOBIL','FLAG_EMP_PHONE','FLAG_WORK_PHONE','FLAG_CONT_MOBILE','FLAG_EMAIL',\\\n",
    "                       'CNT_FAM_MEMBERS','REGION_RATING_CLIENT','REGION_RATING_CLIENT_W_CITY','REG_REGION_NOT_LIVE_REGION',\\\n",
    "                       'REG_REGION_NOT_WORK_REGION','DEF_30_CNT_SOCIAL_CIRCLE','DEF_60_CNT_SOCIAL_CIRCLE','FLAG_DOCUMENT_2',\\\n",
    "                       'FLAG_DOCUMENT_3','FLAG_DOCUMENT_6','FLAG_DOCUMENT_8','AMT_REQ_CREDIT_BUREAU_HOUR',\\\n",
    "                       'AMT_REQ_CREDIT_BUREAU_DAY','AMT_REQ_CREDIT_BUREAU_WEEK','AMT_REQ_CREDIT_BUREAU_QRT',\\\n",
    "                        'REGION_POPULATION_RELATIVE','employment_years','DAYS_REGISTRATION','DAYS_ID_PUBLISH',\\\n",
    "                        'HOUR_APPR_PROCESS_START','EXT_SOURCE_1','EXT_SOURCE_2','EXT_SOURCE_3','DAYS_LAST_PHONE_CHANGE',\\\n",
    "                        'AMT_REQ_CREDIT_BUREAU_MON','AMT_REQ_CREDIT_BUREAU_YEAR',\\\n",
    "                        'AMT_CREDIT_AMT_INCOME_TOTAL_ratio','Client_Age','AMT_ANNUITY_AMT_INCOME_TOTAL_ratio',\\\n",
    "                        'AMT_CREDIT_AMT_GOODS_PRICE_ratio','employment_age']\n",
    "\n",
    "Target = \"TARGET\"\n",
    "\n",
    "primary_key = \"SK_ID_CURR\" \n",
    "\n",
    "\n",
    "len(categorical_features)+len(numerical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train = app_train[categorical_features + numerical_features + [Target,primary_key]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Create a small DataFrame with a categorical column\n",
    "df = pd.DataFrame({\n",
    "    'ID': [1, 2, 3, 4, 5],\n",
    "    'Category': ['A', 'B', 'A', 'C', 'B']\n",
    "})\n",
    "\n",
    "# Convert 'Category' column to categorical type\n",
    "df['Category'] = df['Category'].astype('category')\n",
    "\n",
    "# Check data types\n",
    "print(\"Original DataFrame:\")\n",
    "print(df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"test.csv\", index=False)\n",
    "\n",
    "# Read back from CSV\n",
    "df_csv = pd.read_csv(\"test.csv\")\n",
    "\n",
    "print(\"\\nDataFrame after loading CSV:\")\n",
    "print(df_csv.dtypes)  # 'Category' will be 'object' (string)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_parquet(\"test.parquet\")\n",
    "\n",
    "# Read back from Parquet\n",
    "df_parquet = pd.read_parquet(\"test.parquet\")\n",
    "\n",
    "print(\"\\nDataFrame after loading Parquet:\")\n",
    "print(df_parquet.dtypes)  # 'Category' remains 'category'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
